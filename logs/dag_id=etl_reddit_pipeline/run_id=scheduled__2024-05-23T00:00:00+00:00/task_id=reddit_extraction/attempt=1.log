[2024-05-24T00:59:28.499+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-24T00:59:28.526+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction scheduled__2024-05-23T00:00:00+00:00 [queued]>
[2024-05-24T00:59:28.533+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction scheduled__2024-05-23T00:00:00+00:00 [queued]>
[2024-05-24T00:59:28.534+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-05-24T00:59:28.547+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-05-23 00:00:00+00:00
[2024-05-24T00:59:28.554+0000] {standard_task_runner.py:63} INFO - Started process 74 to run task
[2024-05-24T00:59:28.560+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'scheduled__2024-05-23T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmpg3527qw_']
[2024-05-24T00:59:28.563+0000] {standard_task_runner.py:91} INFO - Job 15: Subtask reddit_extraction
[2024-05-24T00:59:28.618+0000] {task_command.py:426} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction scheduled__2024-05-23T00:00:00+00:00 [running]> on host f174faf60ef4
[2024-05-24T00:59:29.039+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='OlivierAssiene' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-05-23T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-23T00:00:00+00:00'
[2024-05-24T00:59:29.040+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-24T00:59:29.908+0000] {logging_mixin.py:188} INFO - Connected successfully to Reddit!
[2024-05-24T07:45:02.365+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'When do you prefer to use SQL vs Python, what usually are the main determining factors?', 'author_fullname': 't2_lnwagoki', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'When do you prefer SQL or Python for Data Engineering?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cywpgw', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.88, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 86, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 86, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716480933.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>When do you prefer to use SQL vs Python, what usually are the main determining factors?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cywpgw', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='AMDataLake'), 'discussion_type': None, 'num_comments': 117, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cywpgw/when_do_you_prefer_sql_or_python_for_data/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cywpgw/when_do_you_prefer_sql_or_python_for_data/', 'subreddit_subscribers': 185504, 'created_utc': 1716480933.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.376+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'With 14+ years of experience and no calls, how can I land a Data Engineering Manager role at a FAANG company or in a $250k+ job? What steps should I take to prepare myself in an year', 'author_fullname': 't2_4xo4smxw', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What exactly does a Data Engineering Manager at a FAANG company or in a $250k+ role do day-to-day', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyz8gm', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.85, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 84, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 84, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716487243.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>With 14+ years of experience and no calls, how can I land a Data Engineering Manager role at a FAANG company or in a $250k+ job? What steps should I take to prepare myself in an year</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1cyz8gm', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='theant97'), 'discussion_type': None, 'num_comments': 61, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyz8gm/what_exactly_does_a_data_engineering_manager_at_a/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyz8gm/what_exactly_does_a_data_engineering_manager_at_a/', 'subreddit_subscribers': 185504, 'created_utc': 1716487243.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.377+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I hit publish on a blogpost last week on running Spark, Dask, DuckDB, and Polars on the TPC-H benchmark across a variety of scales (10 GiB, 100 GiB, 1 TiB, 10 TiB), both locally on a Macbook Pro and on the cloud.\xa0 It‚Äôs a broad set of configurations.\xa0 The results are interesting.\n\nNo project wins uniformly.\xa0 They all perform differently at different scales:\xa0\n\n* DuckDB and Polars are crazy fast on local machines\n* Dask and DuckDB seem to win on cloud and at scale\n* Dask ends up being most robust, especially at scale\n* DuckDB does shockingly well on large datasets on a single large machine\n* Spark performs oddly poorly, despite being the standard choice üò¢\n\nTons of charts in this post to try to make sense of the data.\xa0 If folks are curious, here‚Äôs the post:\n\n[https://docs.coiled.io/blog/tpch.html](https://docs.coiled.io/blog/tpch.html)\n\nPerformance isn‚Äôt everything of course.\xa0 Each project has its die-hard fans/critics for loads of different reasons.  Anyone want to attack/defend their dataframe library of choice?', 'author_fullname': 't2_ay1q1', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'TPC-H Cloud Benchmarks: Spark, Dask, DuckDB, Polars', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyqe2z', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 50, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 50, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716463312.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I hit publish on a blogpost last week on running Spark, Dask, DuckDB, and Polars on the TPC-H benchmark across a variety of scales (10 GiB, 100 GiB, 1 TiB, 10 TiB), both locally on a Macbook Pro and on the cloud.\xa0 It‚Äôs a broad set of configurations.\xa0 The results are interesting.</p>\n\n<p>No project wins uniformly.\xa0 They all perform differently at different scales:\xa0</p>\n\n<ul>\n<li>DuckDB and Polars are crazy fast on local machines</li>\n<li>Dask and DuckDB seem to win on cloud and at scale</li>\n<li>Dask ends up being most robust, especially at scale</li>\n<li>DuckDB does shockingly well on large datasets on a single large machine</li>\n<li>Spark performs oddly poorly, despite being the standard choice üò¢</li>\n</ul>\n\n<p>Tons of charts in this post to try to make sense of the data.\xa0 If folks are curious, here‚Äôs the post:</p>\n\n<p><a href="https://docs.coiled.io/blog/tpch.html">https://docs.coiled.io/blog/tpch.html</a></p>\n\n<p>Performance isn‚Äôt everything of course.\xa0 Each project has its die-hard fans/critics for loads of different reasons.  Anyone want to attack/defend their dataframe library of choice?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1cyqe2z', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='mrocklin'), 'discussion_type': None, 'num_comments': 28, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyqe2z/tpch_cloud_benchmarks_spark_dask_duckdb_polars/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyqe2z/tpch_cloud_benchmarks_spark_dask_duckdb_polars/', 'subreddit_subscribers': 185504, 'created_utc': 1716463312.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.377+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '[https://www.getorchestra.io/blog/how-i-use-gen-ai-as-a-data-engineer](https://www.getorchestra.io/blog/how-i-use-gen-ai-as-a-data-engineer)', 'author_fullname': 't2_voma7dkju', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Do you data engineering folks actually use Gen AI or nah', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cypmvq', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.85, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 36, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 36, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716460412.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p><a href="https://www.getorchestra.io/blog/how-i-use-gen-ai-as-a-data-engineer">https://www.getorchestra.io/blog/how-i-use-gen-ai-as-a-data-engineer</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/puiRUsf-gquiaZgEqw3Bx6uewpyUjACFOfjqYPN3_XI.jpg?auto=webp&s=eae44833e540c050e48d6c333f689b8ff31f67d4', 'width': 750, 'height': 500}, 'resolutions': [{'url': 'https://external-preview.redd.it/puiRUsf-gquiaZgEqw3Bx6uewpyUjACFOfjqYPN3_XI.jpg?width=108&crop=smart&auto=webp&s=8636934c587f38e716032e35bea35d444bf950c6', 'width': 108, 'height': 72}, {'url': 'https://external-preview.redd.it/puiRUsf-gquiaZgEqw3Bx6uewpyUjACFOfjqYPN3_XI.jpg?width=216&crop=smart&auto=webp&s=70ae2b8562ea1b6ac76900e2316483d0931a520c', 'width': 216, 'height': 144}, {'url': 'https://external-preview.redd.it/puiRUsf-gquiaZgEqw3Bx6uewpyUjACFOfjqYPN3_XI.jpg?width=320&crop=smart&auto=webp&s=0ba38bc791a31a21419927084bd5df9ca21f9164', 'width': 320, 'height': 213}, {'url': 'https://external-preview.redd.it/puiRUsf-gquiaZgEqw3Bx6uewpyUjACFOfjqYPN3_XI.jpg?width=640&crop=smart&auto=webp&s=b2ccf9a0985c452b2fe73a6963ced40b76902944', 'width': 640, 'height': 426}], 'variants': {}, 'id': 'y4ZEyKIlQB0L6msrDysy9vqIo8Lpz7--ShFVsBFaKf8'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1cypmvq', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='engineer_of-sorts'), 'discussion_type': None, 'num_comments': 39, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cypmvq/do_you_data_engineering_folks_actually_use_gen_ai/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cypmvq/do_you_data_engineering_folks_actually_use_gen_ai/', 'subreddit_subscribers': 185504, 'created_utc': 1716460412.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.378+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'My understanding of tools like Databricks Unity Catalog and Athena are (among other things) they let you keep your data sitting e.g. in a bunch of S3 buckets and you can run spark queries across them as if they were in a database. This is appealing because you don‚Äôt have to load them into a ‚Äúwarehouse‚Äù. \n\n  \nIs that an important and common pattern typically? Are there good open source solutions that address this need? Or is it mostly whatever‚Äôs native to the cloud vendor?\n\nEdit: thank you for all the feedback!', 'author_fullname': 't2_68lzmocg', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How are we feeling about ‚ÄúLakehouse‚Äù solutions', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cz3m7f', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.84, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 17, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 17, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1716525628.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716498129.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>My understanding of tools like Databricks Unity Catalog and Athena are (among other things) they let you keep your data sitting e.g. in a bunch of S3 buckets and you can run spark queries across them as if they were in a database. This is appealing because you don‚Äôt have to load them into a ‚Äúwarehouse‚Äù. </p>\n\n<p>Is that an important and common pattern typically? Are there good open source solutions that address this need? Or is it mostly whatever‚Äôs native to the cloud vendor?</p>\n\n<p>Edit: thank you for all the feedback!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cz3m7f', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='LeisureActivities'), 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cz3m7f/how_are_we_feeling_about_lakehouse_solutions/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cz3m7f/how_are_we_feeling_about_lakehouse_solutions/', 'subreddit_subscribers': 185504, 'created_utc': 1716498129.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.378+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hello all, we are currently running a GCP house in our company. We are using Bigquery as data warehouse and Cloud Composer for pipeline orchestration. \n\nWe do take advantage of the various Bigquery operators for parameterising/templating queries and to create tables if needed. \n\nMy question is, I have been reading a lot about DBT and how it can help us become more efficient. \n\nCan you  give me feedback/ideas on how it can help us data engineer or reduce our cloud costs? ', 'author_fullname': 't2_esibz', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'DBT needed?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyp62o', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 17, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 17, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716458517.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello all, we are currently running a GCP house in our company. We are using Bigquery as data warehouse and Cloud Composer for pipeline orchestration. </p>\n\n<p>We do take advantage of the various Bigquery operators for parameterising/templating queries and to create tables if needed. </p>\n\n<p>My question is, I have been reading a lot about DBT and how it can help us become more efficient. </p>\n\n<p>Can you  give me feedback/ideas on how it can help us data engineer or reduce our cloud costs? </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cyp62o', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='ithellam_oru_pollapu'), 'discussion_type': None, 'num_comments': 21, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyp62o/dbt_needed/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyp62o/dbt_needed/', 'subreddit_subscribers': 185504, 'created_utc': 1716458517.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.378+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'So the request is in the title. We have unit tests where needed, always chipping away at it without getting carried away. This is primarily for ingestion, parsing, flattening, schema validation, etc‚Ä¶. All the stuff where Python works great. \n\nEventually we get into data quality transformations, business logic transformations, and this stuff is generally executed as a series of complex SQL scripts on the data. \n\nThere are always edge cases out there that are unknown at the time of development. So we fix the issue, but generally we‚Äôre not adding a test. \n\nWhat are your recommendations on how you would handle this scenario. What frameworks are you using, specifically for SQL based transformations. Stuff that would be excruciating to do in a DF context. ', 'author_fullname': 't2_ibioowgs', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Testing framework recommendations for complex SQL transformations', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1czb6cb', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.95, 'author_flair_background_color': 'transparent', 'subreddit_type': 'public', 'ups': 14, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': '08789422-ac9d-11eb-aade-0e32c0bdd4fb', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 14, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716520465.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>So the request is in the title. We have unit tests where needed, always chipping away at it without getting carried away. This is primarily for ingestion, parsing, flattening, schema validation, etc‚Ä¶. All the stuff where Python works great. </p>\n\n<p>Eventually we get into data quality transformations, business logic transformations, and this stuff is generally executed as a series of complex SQL scripts on the data. </p>\n\n<p>There are always edge cases out there that are unknown at the time of development. So we fix the issue, but generally we‚Äôre not adding a test. </p>\n\n<p>What are your recommendations on how you would handle this scenario. What frameworks are you using, specifically for SQL based transformations. Stuff that would be excruciating to do in a DF context. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Big Data Engineer', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1czb6cb', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='SDFP-A'), 'discussion_type': None, 'num_comments': 15, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1czb6cb/testing_framework_recommendations_for_complex_sql/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1czb6cb/testing_framework_recommendations_for_complex_sql/', 'subreddit_subscribers': 185504, 'created_utc': 1716520465.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.378+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "For me, it's [Airbnb's article introducing Minerva](https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70). Coming from startups (and the quirks such environments have for data infrastructure), reading about the details of their approach to metrics and analytics was eye opening. It was one of the articles that pushed me from data science to data engineering.\n\nedit: fixing link ", 'author_fullname': 't2_v7fvlqc8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': "What's your favorite article from a technical blog?", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1czb0m6', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 13, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 13, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716519912.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>For me, it&#39;s <a href="https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70">Airbnb&#39;s article introducing Minerva</a>. Coming from startups (and the quirks such environments have for data infrastructure), reading about the details of their approach to metrics and analytics was eye opening. It was one of the articles that pushed me from data science to data engineering.</p>\n\n<p>edit: fixing link </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/nIpek7S4QjlB-uAtg4xrv_6Z2EHPwLC5v4jVV3KpKDY.jpg?auto=webp&s=c25ad09223422a6fcaecaed4d87eedf196dfcb2f', 'width': 1200, 'height': 486}, 'resolutions': [{'url': 'https://external-preview.redd.it/nIpek7S4QjlB-uAtg4xrv_6Z2EHPwLC5v4jVV3KpKDY.jpg?width=108&crop=smart&auto=webp&s=68a32f79714d9d58a14d33ef02ebd9acc603c374', 'width': 108, 'height': 43}, {'url': 'https://external-preview.redd.it/nIpek7S4QjlB-uAtg4xrv_6Z2EHPwLC5v4jVV3KpKDY.jpg?width=216&crop=smart&auto=webp&s=742fd23ae40a0b4f6bb77b9214992cfda69c2a10', 'width': 216, 'height': 87}, {'url': 'https://external-preview.redd.it/nIpek7S4QjlB-uAtg4xrv_6Z2EHPwLC5v4jVV3KpKDY.jpg?width=320&crop=smart&auto=webp&s=1b2f57101d7a8692667073aa0d08d817405a341e', 'width': 320, 'height': 129}, {'url': 'https://external-preview.redd.it/nIpek7S4QjlB-uAtg4xrv_6Z2EHPwLC5v4jVV3KpKDY.jpg?width=640&crop=smart&auto=webp&s=47f275104c2d7ee5f9f1e1d47b47f8b1080e8cb1', 'width': 640, 'height': 259}, {'url': 'https://external-preview.redd.it/nIpek7S4QjlB-uAtg4xrv_6Z2EHPwLC5v4jVV3KpKDY.jpg?width=960&crop=smart&auto=webp&s=6546dccdb2e4c68b6c77e5f84e326dd4aa7633bc', 'width': 960, 'height': 388}, {'url': 'https://external-preview.redd.it/nIpek7S4QjlB-uAtg4xrv_6Z2EHPwLC5v4jVV3KpKDY.jpg?width=1080&crop=smart&auto=webp&s=32a2c87e7dd54b107a7a3c808429f8f5170165dc', 'width': 1080, 'height': 437}], 'variants': {}, 'id': 'sNCfbVx7JRVM8NrBSGqH-_p7z5Ri2NBpIUwnHh2WCpc'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1czb0m6', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='on_the_mark_data'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1czb0m6/whats_your_favorite_article_from_a_technical_blog/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1czb0m6/whats_your_favorite_article_from_a_technical_blog/', 'subreddit_subscribers': 185504, 'created_utc': 1716519912.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.379+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Just wrote duplicate handling approaches that I have been using in the past recent years.\n\nPlease give it a read, correct me if I am wrong and provide feedback.\n\nThanks üòä', 'author_fullname': 't2_dhgy4', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Handling Duplicates In Streaming Pipeline', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 70, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cz63dv', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'ups': 11, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 11, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/rQNMzPImyegC2QpUjWjxGHZuuJZGNL_ppkIiUaJ_bus.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'link', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1716504663.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'junaideffendi.com', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Just wrote duplicate handling approaches that I have been using in the past recent years.</p>\n\n<p>Please give it a read, correct me if I am wrong and provide feedback.</p>\n\n<p>Thanks üòä</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.junaideffendi.com/p/handling-duplicates-in-streaming', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/H-MAPBD78LVAFiNGRl0pkN4PDCaC9QFudf1sBa9Ye-k.jpg?auto=webp&s=8b740be52ed189b8b442ae3f0d353cc2609e1721', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/H-MAPBD78LVAFiNGRl0pkN4PDCaC9QFudf1sBa9Ye-k.jpg?width=108&crop=smart&auto=webp&s=b061371469310008b87893713b6567258c9729d3', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/H-MAPBD78LVAFiNGRl0pkN4PDCaC9QFudf1sBa9Ye-k.jpg?width=216&crop=smart&auto=webp&s=d71b1e0b8a54a7d723e827966bdd9c7ce4b7507a', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/H-MAPBD78LVAFiNGRl0pkN4PDCaC9QFudf1sBa9Ye-k.jpg?width=320&crop=smart&auto=webp&s=16918e7f31ba333e911a2f452dc4533fcdac06b1', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/H-MAPBD78LVAFiNGRl0pkN4PDCaC9QFudf1sBa9Ye-k.jpg?width=640&crop=smart&auto=webp&s=937d65d988d7d017ab5f70200edbf79065558de9', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/H-MAPBD78LVAFiNGRl0pkN4PDCaC9QFudf1sBa9Ye-k.jpg?width=960&crop=smart&auto=webp&s=b24d74e7fad6d66b537a8703bb85a4ff1e4688a3', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/H-MAPBD78LVAFiNGRl0pkN4PDCaC9QFudf1sBa9Ye-k.jpg?width=1080&crop=smart&auto=webp&s=9d34a20ac4e85abff0d3cc433852ad6af87d90bf', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'S2Sqnqf7JPTShkLbsKAu5f5uHnt5gUNKoRf2UDiJfo0'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1cz63dv', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='mjfnd'), 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cz63dv/handling_duplicates_in_streaming_pipeline/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.junaideffendi.com/p/handling-duplicates-in-streaming', 'subreddit_subscribers': 185504, 'created_utc': 1716504663.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.379+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hey all -- \n\nSo I work in a manufacturing / research setting, where we have constant streams of time series data coming off of "test stands" measuring things like temperature, etc.\n\nRight now we store it in an on-prem Postgres database using Timescale, with other information about tests that were performed in another, separate Postgres database.\n\nTo analyze data, scientists and engineers note the start and stop time of their test in that other Postgres database, with data being transformed and prepared whenever they download that "test". \n\nSince transforming data and doing calculations on data at the time of request has become expensive and somewhat slow, I want to store these chunks of processed time series data for consumption.\n\nCan anyone tell me the best way to do this? Ideally we\'d also like to be able to grab only parts of that chunk, as well.\n\nWould it be S3? Another relational database? I tried using Postgres JSONB columns on a whim, but insertion is super slow and there\'s the possibility of hitting the upper limit in terms of size.\n\nAppreciate any help!\n\n', 'author_fullname': 't2_o8rziw7x', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Best way to store chunks of time series data', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyvj2g', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.91, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 8, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 8, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716478034.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey all -- </p>\n\n<p>So I work in a manufacturing / research setting, where we have constant streams of time series data coming off of &quot;test stands&quot; measuring things like temperature, etc.</p>\n\n<p>Right now we store it in an on-prem Postgres database using Timescale, with other information about tests that were performed in another, separate Postgres database.</p>\n\n<p>To analyze data, scientists and engineers note the start and stop time of their test in that other Postgres database, with data being transformed and prepared whenever they download that &quot;test&quot;. </p>\n\n<p>Since transforming data and doing calculations on data at the time of request has become expensive and somewhat slow, I want to store these chunks of processed time series data for consumption.</p>\n\n<p>Can anyone tell me the best way to do this? Ideally we&#39;d also like to be able to grab only parts of that chunk, as well.</p>\n\n<p>Would it be S3? Another relational database? I tried using Postgres JSONB columns on a whim, but insertion is super slow and there&#39;s the possibility of hitting the upper limit in terms of size.</p>\n\n<p>Appreciate any help!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cyvj2g', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='bad_specimen'), 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyvj2g/best_way_to_store_chunks_of_time_series_data/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyvj2g/best_way_to_store_chunks_of_time_series_data/', 'subreddit_subscribers': 185504, 'created_utc': 1716478034.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.380+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '', 'author_fullname': 't2_crthfc7kd', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Free database design tool  - DrawDB', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 78, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1czbui1', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.88, 'author_flair_background_color': 'transparent', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': 'fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/GHIsHFezvvyc39NFWBSLQnjvsHMeyakPADF5Tg-P4FQ.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'link', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1716522820.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'drawdb.vercel.app', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://drawdb.vercel.app/', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/rOPacuxVU_avVrY6jlPGI0sr_XOCok3tx5RZRqm2lbU.jpg?auto=webp&s=ffe5d6f80ad7000663e4950d1dc003f9d58887b7', 'width': 1565, 'height': 872}, 'resolutions': [{'url': 'https://external-preview.redd.it/rOPacuxVU_avVrY6jlPGI0sr_XOCok3tx5RZRqm2lbU.jpg?width=108&crop=smart&auto=webp&s=efdc07c4d3c0db11f340151c62adf2d1047713ba', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/rOPacuxVU_avVrY6jlPGI0sr_XOCok3tx5RZRqm2lbU.jpg?width=216&crop=smart&auto=webp&s=59497994b7bbfdb0b5c2c4a08124abf2122f565b', 'width': 216, 'height': 120}, {'url': 'https://external-preview.redd.it/rOPacuxVU_avVrY6jlPGI0sr_XOCok3tx5RZRqm2lbU.jpg?width=320&crop=smart&auto=webp&s=1fa4565159afb44229fdf285b64043549048402e', 'width': 320, 'height': 178}, {'url': 'https://external-preview.redd.it/rOPacuxVU_avVrY6jlPGI0sr_XOCok3tx5RZRqm2lbU.jpg?width=640&crop=smart&auto=webp&s=701c897d009dd46a0329c87eb553a0ce05fe18f2', 'width': 640, 'height': 356}, {'url': 'https://external-preview.redd.it/rOPacuxVU_avVrY6jlPGI0sr_XOCok3tx5RZRqm2lbU.jpg?width=960&crop=smart&auto=webp&s=d4fce44755418fe9d8ec101027aadfc16d52cb49', 'width': 960, 'height': 534}, {'url': 'https://external-preview.redd.it/rOPacuxVU_avVrY6jlPGI0sr_XOCok3tx5RZRqm2lbU.jpg?width=1080&crop=smart&auto=webp&s=01b28d4669eabdc42c25789d1573738af16c5315', 'width': 1080, 'height': 601}], 'variants': {}, 'id': 'lQkzuKAZN_obHwB8zuNTldPhM68LLIfD4iI7VqIgQSs'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Data Engineer', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1czbui1', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='devschema'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1czbui1/free_database_design_tool_drawdb/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://drawdb.vercel.app/', 'subreddit_subscribers': 185504, 'created_utc': 1716522820.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.380+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I\'ll be asked to discuss how to model some tables for analytics (digital marketing). Basically "what will the final tables look like, what will the staging tables look like". I\'m a DA not a DE, I don\'t do any real staging with real tech - the closest concept I can get is less-aggregated, normalized(ish) SQL tables being joined and unioned together into an aggregated, unnomarlized SQL table.\n\nHowever, for a real DE actually working at the staging \'stage\' of the ETL process, what considerations go into this? Will the staging tables be materially different from the final? My understanding staging sits right in between inputs: (potentially) unstructured data from different systems and outputs: tabular data. But based on the framing of the question, the conversion of unstructured to structured has already happened (i.e. it\'s tabular). I don\'t know what else can be done to the data. I know there\'s imputation/reformatting but I don\'t think any of those will affect what fields are in the table.\n\nFor examples lets say we\'re working with click data on our app mInstagram.', 'author_fullname': 't2_orafv', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Example of how tables at staging differ from final warehouse tables?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyytik', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716486189.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;ll be asked to discuss how to model some tables for analytics (digital marketing). Basically &quot;what will the final tables look like, what will the staging tables look like&quot;. I&#39;m a DA not a DE, I don&#39;t do any real staging with real tech - the closest concept I can get is less-aggregated, normalized(ish) SQL tables being joined and unioned together into an aggregated, unnomarlized SQL table.</p>\n\n<p>However, for a real DE actually working at the staging &#39;stage&#39; of the ETL process, what considerations go into this? Will the staging tables be materially different from the final? My understanding staging sits right in between inputs: (potentially) unstructured data from different systems and outputs: tabular data. But based on the framing of the question, the conversion of unstructured to structured has already happened (i.e. it&#39;s tabular). I don&#39;t know what else can be done to the data. I know there&#39;s imputation/reformatting but I don&#39;t think any of those will affect what fields are in the table.</p>\n\n<p>For examples lets say we&#39;re working with click data on our app mInstagram.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cyytik', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='fittyfive9'), 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyytik/example_of_how_tables_at_staging_differ_from/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyytik/example_of_how_tables_at_staging_differ_from/', 'subreddit_subscribers': 185504, 'created_utc': 1716486189.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.380+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I was going to adopt data-diff as a tool to improve our CI CD in the next few months. My goal of using it is mostly to figure out whether the PR is going to drastically affect the row count, so I can take it as an alert for the developed feature.\n\nBut now that data-diff has been sunset, is there any similar tools out there that can solve the requirements above?\n\nThank you for reading.', 'author_fullname': 't2_tf5qdee5d', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Tool as a data-diff alternative?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyn2a6', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716449406.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I was going to adopt data-diff as a tool to improve our CI CD in the next few months. My goal of using it is mostly to figure out whether the PR is going to drastically affect the row count, so I can take it as an alert for the developed feature.</p>\n\n<p>But now that data-diff has been sunset, is there any similar tools out there that can solve the requirements above?</p>\n\n<p>Thank you for reading.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cyn2a6', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='SeaCompetitive5704'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyn2a6/tool_as_a_datadiff_alternative/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyn2a6/tool_as_a_datadiff_alternative/', 'subreddit_subscribers': 185504, 'created_utc': 1716449406.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.381+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Am looking to learn glue end to end. Are there resources to learn apart from the aws documentation?', 'author_fullname': 't2_6n03d0sf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Any resources to learn AWS glue.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyyf6y', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716485186.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Am looking to learn glue end to end. Are there resources to learn apart from the aws documentation?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cyyf6y', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='arunrajan96'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyyf6y/any_resources_to_learn_aws_glue/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyyf6y/any_resources_to_learn_aws_glue/', 'subreddit_subscribers': 185504, 'created_utc': 1716485186.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.381+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Collected 5 book recs about real-time/streaming systems for those interested in diving deep into the domain: [https://www.arecadata.com/top-5-books-to-study-real-time-data-systems/](https://www.arecadata.com/top-5-books-to-study-real-time-data-systems/)\n\n', 'author_fullname': 't2_cqao8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '5 books to learn real-time systems', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyvi3o', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716477971.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Collected 5 book recs about real-time/streaming systems for those interested in diving deep into the domain: <a href="https://www.arecadata.com/top-5-books-to-study-real-time-data-systems/">https://www.arecadata.com/top-5-books-to-study-real-time-data-systems/</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/oIYIWuUozh1bva2OCzLuLKGNSELenzek7QlTZQKLpok.jpg?auto=webp&s=93a551ee1ff2e736a4b02e427e25ba0593499309', 'width': 1071, 'height': 683}, 'resolutions': [{'url': 'https://external-preview.redd.it/oIYIWuUozh1bva2OCzLuLKGNSELenzek7QlTZQKLpok.jpg?width=108&crop=smart&auto=webp&s=0f9a61dece70f965cb79fd9fad4da6725b4a1396', 'width': 108, 'height': 68}, {'url': 'https://external-preview.redd.it/oIYIWuUozh1bva2OCzLuLKGNSELenzek7QlTZQKLpok.jpg?width=216&crop=smart&auto=webp&s=f0e448bda9d868a171353e4066e79dd72385a299', 'width': 216, 'height': 137}, {'url': 'https://external-preview.redd.it/oIYIWuUozh1bva2OCzLuLKGNSELenzek7QlTZQKLpok.jpg?width=320&crop=smart&auto=webp&s=99903a210e84038aca14a2a1a342227de979e95a', 'width': 320, 'height': 204}, {'url': 'https://external-preview.redd.it/oIYIWuUozh1bva2OCzLuLKGNSELenzek7QlTZQKLpok.jpg?width=640&crop=smart&auto=webp&s=a6e1b8f52dba13d2e2c14d87fb7e57f5213547c1', 'width': 640, 'height': 408}, {'url': 'https://external-preview.redd.it/oIYIWuUozh1bva2OCzLuLKGNSELenzek7QlTZQKLpok.jpg?width=960&crop=smart&auto=webp&s=1a8fb2f4b4d956489a266ccd03375359cf78220a', 'width': 960, 'height': 612}], 'variants': {}, 'id': 'mcVhpxKhiQ14moph36EepMTPfhbbIHL5hdV-E8lyiLE'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1cyvi3o', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='dan_the_lion'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyvi3o/5_books_to_learn_realtime_systems/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyvi3o/5_books_to_learn_realtime_systems/', 'subreddit_subscribers': 185504, 'created_utc': 1716477971.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.381+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I need a library of connectors to query data from various sources like MySQL, Snowflake, Redshift, Databricks, etc.\n\nSomething similar to [these connectors in Apache Beam](https://beam.apache.org/documentation/io/connectors/).\n\nSome other constraints:\n\n* should support Java\n* should be open-source\n* should be scalable to query large data volumes(peak volume in a query may reach a few GBs)\n* should have support for self-hosting (cannot put customer's data in a 3rd party's cloud)\n\nDoes anyone know if something like this exists?\n\nAnd as a follow-up, can I just use Apache Beam itself for this usecase? I want to use Beam only for its connectors to query the data and store it in something like S3/SQS for further processing.", 'author_fullname': 't2_14n4z8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Is there any open-source connectors library that I can use for fetching data from various different data sources?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cz1rqr', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716493517.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I need a library of connectors to query data from various sources like MySQL, Snowflake, Redshift, Databricks, etc.</p>\n\n<p>Something similar to <a href="https://beam.apache.org/documentation/io/connectors/">these connectors in Apache Beam</a>.</p>\n\n<p>Some other constraints:</p>\n\n<ul>\n<li>should support Java</li>\n<li>should be open-source</li>\n<li>should be scalable to query large data volumes(peak volume in a query may reach a few GBs)</li>\n<li>should have support for self-hosting (cannot put customer&#39;s data in a 3rd party&#39;s cloud)</li>\n</ul>\n\n<p>Does anyone know if something like this exists?</p>\n\n<p>And as a follow-up, can I just use Apache Beam itself for this usecase? I want to use Beam only for its connectors to query the data and store it in something like S3/SQS for further processing.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cz1rqr', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='lightt77'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cz1rqr/is_there_any_opensource_connectors_library_that_i/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cz1rqr/is_there_any_opensource_connectors_library_that_i/', 'subreddit_subscribers': 185504, 'created_utc': 1716493517.0, 'num_crossposts': 1, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.382+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hey everyone,\n\nI have a bit of time at my hands at the moment and I kind of want to also work on my open source contribution portfolio a bit and I was wondering if you are doing or know like early - mid stage open source projects in data engineering that I could look into ?\n\n  \nThank you', 'author_fullname': 't2_140q2y', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Open source projects', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1czemnj', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.8, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Open Source', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716533500.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey everyone,</p>\n\n<p>I have a bit of time at my hands at the moment and I kind of want to also work on my open source contribution portfolio a bit and I was wondering if you are doing or know like early - mid stage open source projects in data engineering that I could look into ?</p>\n\n<p>Thank you</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '3957ca64-3440-11ed-8329-2aa6ad243a59', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#005ba1', 'id': '1czemnj', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='alpaman'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1czemnj/open_source_projects/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1czemnj/open_source_projects/', 'subreddit_subscribers': 185504, 'created_utc': 1716533500.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.382+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '', 'author_fullname': 't2_crthfc7kd', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How do you help analysts review their PRs on your data project? Is it needed?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 78, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1czbq04', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.75, 'author_flair_background_color': 'transparent', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': 'fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://a.thumbs.redditmedia.com/V3OvNZibEEa_X5aHAHJXKu3vMxBbjs6j4DzZKzMwkB0.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'link', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1716522369.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'medium.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://medium.com/inthepipeline/self-serve-review-for-self-serve-data-06b606e90cce', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/1wsQbkG0d4r-FhriWVMwJuaXmPg0v7XhodiK0ZuVnjw.jpg?auto=webp&s=f838a2059a181910d799d2e1f81629b6ea0f7370', 'width': 1200, 'height': 674}, 'resolutions': [{'url': 'https://external-preview.redd.it/1wsQbkG0d4r-FhriWVMwJuaXmPg0v7XhodiK0ZuVnjw.jpg?width=108&crop=smart&auto=webp&s=fe8f8b27781e201dd0b247b086640bb98aca6901', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/1wsQbkG0d4r-FhriWVMwJuaXmPg0v7XhodiK0ZuVnjw.jpg?width=216&crop=smart&auto=webp&s=81d453ad48dc4e5fbe23a7efdbb161844866b1ef', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/1wsQbkG0d4r-FhriWVMwJuaXmPg0v7XhodiK0ZuVnjw.jpg?width=320&crop=smart&auto=webp&s=65afb6c5febf0891c7562328fbb4240fcec69d42', 'width': 320, 'height': 179}, {'url': 'https://external-preview.redd.it/1wsQbkG0d4r-FhriWVMwJuaXmPg0v7XhodiK0ZuVnjw.jpg?width=640&crop=smart&auto=webp&s=30d5439086c280c41f6b818d0fd18577489aeede', 'width': 640, 'height': 359}, {'url': 'https://external-preview.redd.it/1wsQbkG0d4r-FhriWVMwJuaXmPg0v7XhodiK0ZuVnjw.jpg?width=960&crop=smart&auto=webp&s=6ac904feffc96ab2a1e6a459121bdbab0f7738a5', 'width': 960, 'height': 539}, {'url': 'https://external-preview.redd.it/1wsQbkG0d4r-FhriWVMwJuaXmPg0v7XhodiK0ZuVnjw.jpg?width=1080&crop=smart&auto=webp&s=e2161df079eeb9c49ec7db0417b1561737e688fb', 'width': 1080, 'height': 606}], 'variants': {}, 'id': 'wf2bCnbLa17oDm_NMKffwLexCT3WJdA2-PvLX5UPA3A'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Data Engineer', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1czbq04', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='devschema'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1czbq04/how_do_you_help_analysts_review_their_prs_on_your/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://medium.com/inthepipeline/self-serve-review-for-self-serve-data-06b606e90cce', 'subreddit_subscribers': 185504, 'created_utc': 1716522369.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.383+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hello, I have a project where I have to do some small data engineering in Django ORM for a social media project but I‚Äôve little knowledge of the area.\n\nWhat I have to do is come up with a schema for storing which other users a user has blocked. I cannot use a separate table like block(user, other_user) due to some Apple regulation (?). So it has to be included in the user table.\n\nRight now I have either:\nA) a longtext column in the form of a csv, just rows of emails or UUIDs.\n\nB) JSONField that is just a list of emails/UUIDs.\n\nI understand that JSON is used to represent complex hierarchy of info and CSV for simplicity. So CSV looks better. But manager hinted that JSON can be better? Can anyone explain reasons why. Because I don‚Äôt understand any of the tradeoffs and tricks used to make queries more efficient.\n\nAnother concern is deleted users. Either of these approaches would result in me having to look through every user once in a while to remove every blocked user. That doesn‚Äôt seem to be a good use of maintenance time?\n\nIf the question seems dumb I would appreciate some resources on best practices for situations like this.\n\n', 'author_fullname': 't2_ayo9qi28', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Storing list of blocked UUIDs in MySQL?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cz7881', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716507914.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello, I have a project where I have to do some small data engineering in Django ORM for a social media project but I‚Äôve little knowledge of the area.</p>\n\n<p>What I have to do is come up with a schema for storing which other users a user has blocked. I cannot use a separate table like block(user, other_user) due to some Apple regulation (?). So it has to be included in the user table.</p>\n\n<p>Right now I have either:\nA) a longtext column in the form of a csv, just rows of emails or UUIDs.</p>\n\n<p>B) JSONField that is just a list of emails/UUIDs.</p>\n\n<p>I understand that JSON is used to represent complex hierarchy of info and CSV for simplicity. So CSV looks better. But manager hinted that JSON can be better? Can anyone explain reasons why. Because I don‚Äôt understand any of the tradeoffs and tricks used to make queries more efficient.</p>\n\n<p>Another concern is deleted users. Either of these approaches would result in me having to look through every user once in a while to remove every blocked user. That doesn‚Äôt seem to be a good use of maintenance time?</p>\n\n<p>If the question seems dumb I would appreciate some resources on best practices for situations like this.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cz7881', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Initial-Dark-8919'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cz7881/storing_list_of_blocked_uuids_in_mysql/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cz7881/storing_list_of_blocked_uuids_in_mysql/', 'subreddit_subscribers': 185504, 'created_utc': 1716507914.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.383+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I plan to utilize Materialized Views on Redshift to optimize certain queries. I anticipate refreshing this Materialized View 6-12 times a day.\n\nHowever, I'm unable to find any clear documentation on the behavior of queries that utilize this MV during it refresh.\n\nFor instance, let's assume the MV refresh takes approximately 5 minutes. If I initiate a refresh and simultaneously execute a query against the table (e.g., `SELECT * FROM mv_some_view WHERE some condition`), will the query access the view's state before the REFRESH or will it wait in a queue until the REFRESH completes?\n\nThanks,  \nMP", 'author_fullname': 't2_835lb23v', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How  REFRESH MATERIALIZED VIEW in Redshift works, and how it handles queries during refresh', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cz17jx', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716492124.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I plan to utilize Materialized Views on Redshift to optimize certain queries. I anticipate refreshing this Materialized View 6-12 times a day.</p>\n\n<p>However, I&#39;m unable to find any clear documentation on the behavior of queries that utilize this MV during it refresh.</p>\n\n<p>For instance, let&#39;s assume the MV refresh takes approximately 5 minutes. If I initiate a refresh and simultaneously execute a query against the table (e.g., <code>SELECT * FROM mv_some_view WHERE some condition</code>), will the query access the view&#39;s state before the REFRESH or will it wait in a queue until the REFRESH completes?</p>\n\n<p>Thanks,<br/>\nMP</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cz17jx', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Purple_Wrap9596'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cz17jx/how_refresh_materialized_view_in_redshift_works/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cz17jx/how_refresh_materialized_view_in_redshift_works/', 'subreddit_subscribers': 185504, 'created_utc': 1716492124.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.383+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'My company is migrating to using GCP and BigQuery for their data engineering needs. I am an embedded domain-specific (biology) data scientist with little background of all the data engineering terms being thrown around me these days.\n\nI want to educate myself about this field, what would be a good place to start? I have a fair handle on coding (R, Python, some SQL) and fundamental concepts on relational databases (wrote a full ETL pipeline going to an SQLite database for genome sequencing data). I am completely at sea however with these concepts of data lakes, warehouses, BigQuery, spark etc. \n\nI see google offers certifications, are these valuable? Historical discussions about this topic are quite divisive, curious to hear if that has changed.', 'author_fullname': 't2_s5s0xh', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Tutorials/certs for GCP', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyz0ka', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716486684.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>My company is migrating to using GCP and BigQuery for their data engineering needs. I am an embedded domain-specific (biology) data scientist with little background of all the data engineering terms being thrown around me these days.</p>\n\n<p>I want to educate myself about this field, what would be a good place to start? I have a fair handle on coding (R, Python, some SQL) and fundamental concepts on relational databases (wrote a full ETL pipeline going to an SQLite database for genome sequencing data). I am completely at sea however with these concepts of data lakes, warehouses, BigQuery, spark etc. </p>\n\n<p>I see google offers certifications, are these valuable? Historical discussions about this topic are quite divisive, curious to hear if that has changed.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cyz0ka', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='EuphoricArtichoke'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyz0ka/tutorialscerts_for_gcp/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyz0ka/tutorialscerts_for_gcp/', 'subreddit_subscribers': 185504, 'created_utc': 1716486684.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.383+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I have been looking to purchase a course from Udemy on Airflow. The courses present in Udemy seem to be outdated. I read a couple of reviews and they do mention that some parts of it are outdated. And all the high rated courses I checked were last updated in 2023. Marc Lamberti's courses are the most rated ones. Do you think it will be worth buying the course for Airflow in Udemy?", 'author_fullname': 't2_auriunhuo', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Are Udemy courses on Airflow worth buying? ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cywy80', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.75, 'author_flair_background_color': 'transparent', 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': 'a96f3daa-e787-11ed-bb3c-927138abd1d2', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716481521.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I have been looking to purchase a course from Udemy on Airflow. The courses present in Udemy seem to be outdated. I read a couple of reviews and they do mention that some parts of it are outdated. And all the high rated courses I checked were last updated in 2023. Marc Lamberti&#39;s courses are the most rated ones. Do you think it will be worth buying the course for Airflow in Udemy?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Junior Data Engineer', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cywy80', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Interesting-Rub-3984'), 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1cywy80/are_udemy_courses_on_airflow_worth_buying/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cywy80/are_udemy_courses_on_airflow_worth_buying/', 'subreddit_subscribers': 185504, 'created_utc': 1716481521.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.384+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi, \n\nI am not a data engineer (I work in finance) but I have been using python a lot in my job so far and I consider myself quite decent at it compared to the average of my industry (can use OOP, connection Python to SQL, apply good practices of programming).\n\nI want to increase my skills in the Data Engineering space. I have one project in mind that I want to develop and I was looking for advice on how to structure it and the tools that I need to master for it. The project would look like the following:\n\n- get the quarterly results report from the website of a company (often in pdf format)\n\n- exctract the figures that I want from the report (it might involve storing the reports in another format, e.g. csv)  \n- build visualization output and pass the raw numbers to other tool for further analysis\n\nHappy to hear any feedbacks (yes, I googled already and have asked to ChatGPT too :)). Books recommendations are welcome. Thanks!', 'author_fullname': 't2_wzsqhude7', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Looking for advice on a project to build my DataEngineering stack ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cywv0j', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716481304.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi, </p>\n\n<p>I am not a data engineer (I work in finance) but I have been using python a lot in my job so far and I consider myself quite decent at it compared to the average of my industry (can use OOP, connection Python to SQL, apply good practices of programming).</p>\n\n<p>I want to increase my skills in the Data Engineering space. I have one project in mind that I want to develop and I was looking for advice on how to structure it and the tools that I need to master for it. The project would look like the following:</p>\n\n<ul>\n<li><p>get the quarterly results report from the website of a company (often in pdf format)</p></li>\n<li><p>exctract the figures that I want from the report (it might involve storing the reports in another format, e.g. csv)  </p></li>\n<li><p>build visualization output and pass the raw numbers to other tool for further analysis</p></li>\n</ul>\n\n<p>Happy to hear any feedbacks (yes, I googled already and have asked to ChatGPT too :)). Books recommendations are welcome. Thanks!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cywv0j', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='SurveyIllustrious738'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cywv0j/looking_for_advice_on_a_project_to_build_my/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cywv0j/looking_for_advice_on_a_project_to_build_my/', 'subreddit_subscribers': 185504, 'created_utc': 1716481304.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.384+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hey there, I\'m new to the sub (after discovering what the thing I could never find out how to do properly as part of my Data Projects was called!). I am a student looking to build out projects end to end and gain experience with Open Source tools & Industry Best Practices. \n\nI wanted to hear peoples opinions or experiences regarding Local Compute / Storage options vs Cloud Free Tiers. I have approached Cloud before as partof different projects and it appeared quite intimidating, however I recently considered getting a few raspberry pis or old PCs that I could find lying around and "simulate" them as different components of the system. Like an RBP for Raw Data. An old laptop with CUDA to do the compute further down the line etc. Is this stupid and I should just go an use cloud free tiers, or could this be a worthwhile project for my learning (and a portfolio?). ', 'author_fullname': 't2_o8oegkoct', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Local Compute and Storage vs Cloud for Keen Student', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cypb40', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716459083.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey there, I&#39;m new to the sub (after discovering what the thing I could never find out how to do properly as part of my Data Projects was called!). I am a student looking to build out projects end to end and gain experience with Open Source tools &amp; Industry Best Practices. </p>\n\n<p>I wanted to hear peoples opinions or experiences regarding Local Compute / Storage options vs Cloud Free Tiers. I have approached Cloud before as partof different projects and it appeared quite intimidating, however I recently considered getting a few raspberry pis or old PCs that I could find lying around and &quot;simulate&quot; them as different components of the system. Like an RBP for Raw Data. An old laptop with CUDA to do the compute further down the line etc. Is this stupid and I should just go an use cloud free tiers, or could this be a worthwhile project for my learning (and a portfolio?). </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cypb40', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='CAOCDO'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cypb40/local_compute_and_storage_vs_cloud_for_keen/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cypb40/local_compute_and_storage_vs_cloud_for_keen/', 'subreddit_subscribers': 185504, 'created_utc': 1716459083.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.384+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Trying to learn all about DE and currently looking at the different data model paradigms.\n\nData Vault sounds like the old relational model. It's tables are highly normalized. It has a bit of star/snowflake because there's facts (hubs) and dimensions (satellites), but relationship between tables follows essentially the relational model. Is that correct?", 'author_fullname': 't2_orafv', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Is data vault just relational schema rebranded?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyzpn3', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716488405.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Trying to learn all about DE and currently looking at the different data model paradigms.</p>\n\n<p>Data Vault sounds like the old relational model. It&#39;s tables are highly normalized. It has a bit of star/snowflake because there&#39;s facts (hubs) and dimensions (satellites), but relationship between tables follows essentially the relational model. Is that correct?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cyzpn3', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='fittyfive9'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyzpn3/is_data_vault_just_relational_schema_rebranded/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyzpn3/is_data_vault_just_relational_schema_rebranded/', 'subreddit_subscribers': 185504, 'created_utc': 1716488405.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.384+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Has anyone extracted data from the ticket audit endpoint? I am trying to extract data from it and I use the after_url for pagination and I get the data but it is always data from the last 45 mins. Please help', 'author_fullname': 't2_35f1rdk6', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Zendesk ticket audit endpoint? ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyyibo', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716485404.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Has anyone extracted data from the ticket audit endpoint? I am trying to extract data from it and I use the after_url for pagination and I get the data but it is always data from the last 45 mins. Please help</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cyyibo', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Rogie_88'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyyibo/zendesk_ticket_audit_endpoint/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyyibo/zendesk_ticket_audit_endpoint/', 'subreddit_subscribers': 185504, 'created_utc': 1716485404.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.385+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I am working  in 2 projects where am mainly working as  L2 application support engineer  for a java based application and secondary  responsible is monitoring ETL process scheduled runs in ADF pipelines. Am now planning to move my career from application support to Data Engineer.Since, i have some beginner level familiarity with adf & etl process. Could you guys assist me from where and what topics should i learnand gain knowledge , so i can switch to my next role as data engineer( currently only having knowledge in sql and python without hands-on experience)', 'author_fullname': 't2_jty17j0d', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Need Assistance in Career Transition', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyvevv', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716477740.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I am working  in 2 projects where am mainly working as  L2 application support engineer  for a java based application and secondary  responsible is monitoring ETL process scheduled runs in ADF pipelines. Am now planning to move my career from application support to Data Engineer.Since, i have some beginner level familiarity with adf &amp; etl process. Could you guys assist me from where and what topics should i learnand gain knowledge , so i can switch to my next role as data engineer( currently only having knowledge in sql and python without hands-on experience)</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1cyvevv', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='HelpfulGeologist5007'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyvevv/need_assistance_in_career_transition/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyvevv/need_assistance_in_career_transition/', 'subreddit_subscribers': 185504, 'created_utc': 1716477740.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.385+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hi everyone,\n\nI've been working with Databricks and exploring their Delta Live Tables (DLT) for pipeline orchestration and data engineering. However, I‚Äôve hit a roadblock: it seems that DLT does not support external locations.\n\nI‚Äôm curious to understand why this limitation exists. Are there technical reasons or specific considerations from Databricks' perspective that I might be missing? How do you work around this limitation in your projects?\n\nAny insights or experiences you can share would be greatly appreciated!\n\nThanks in advance!", 'author_fullname': 't2_utq8ecoj', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': "Why Doesn't Databricks DLT Support External Locations?", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyty73', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716474033.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi everyone,</p>\n\n<p>I&#39;ve been working with Databricks and exploring their Delta Live Tables (DLT) for pipeline orchestration and data engineering. However, I‚Äôve hit a roadblock: it seems that DLT does not support external locations.</p>\n\n<p>I‚Äôm curious to understand why this limitation exists. Are there technical reasons or specific considerations from Databricks&#39; perspective that I might be missing? How do you work around this limitation in your projects?</p>\n\n<p>Any insights or experiences you can share would be greatly appreciated!</p>\n\n<p>Thanks in advance!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cyty73', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='JazzlikeReaction631'), 'discussion_type': None, 'num_comments': 9, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyty73/why_doesnt_databricks_dlt_support_external/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyty73/why_doesnt_databricks_dlt_support_external/', 'subreddit_subscribers': 185504, 'created_utc': 1716474033.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.385+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I am working on a project where I scrape data from multiple websites, using a separate \\`.py\\` script for each website. Each script varies certain parameters to perform 'incremental scrapes' while keeping other parameters fixed. For example,\n\n- Website A, I vary parameters like \\`DATE\\_FROM\\` and \\`DATE\\_TO\\` while keeping \\`TITLE\\`, \\`RATING\\`, and \\`PAGE\\_SIZE\\` fixed.\n\n- Website B, I vary \\`YEAR\\` and \\`RATING\\`, and keep \\`TITLE\\` and \\`MAX\\_RESULTS\\` fixed.\n\n- Website C, I don't vary any parameters.\n\n\n\n(In reality there are 50+ sites I am doing this for.)\n\n\n\nThe results are dumped into separate directories for each website (\\`data/website\\_A/\\`, \\`data/website\\_B/\\`, etc.). Currently, I name the output files to include the varied parameters, which has resulted in complex and hard-to-read filenames. For example, in \\`data/website\\_A/\\`, I have filenames like:\n\n\n\n1. \\`1800-01-01\\_2002-01-01\\_loop\\_2002-01-02\\_2005-01-01.csv\\`\n\n2. \\`loop\\_2005-01-02\\_2010-01-01.csv\\`\n\n\n\nwhich is meant to indicate \n\n\n\n1. the scraper runs on \\`DATE\\_FROM = 1800-01-01\\` and \\`DATE\\_TO = 2002-01-01\\`, followed by a loop from \\`DATE\\_FROM = DATE\\_TO = 2002-01-02\\` to \\`DATE\\_FROM = DATE\\_TO = 2005-01-01\\`,\n\n\n\n2. the scraper runs on a loop from \\`DATE\\_FROM = DATE\\_TO = 2005-01-02\\` to \\`DATE\\_FROM = DATE\\_TO = 2010-01-01\\`\n\n\n\nbut from these filenames, it's not immediately clear which parameters were varied and which were kept fixed. \n\n\n\nMy questions are:\n\n\n\n1. What is the best practice for organizing these folders and files so that it's easy to identify which parameters were varied without cluttering the filenames?\n\n2. Is there a recommended way to log the parameters, both varied and fixed, for each scrape in a clear and maintainable manner?\n\n\n\nIt seems like I will have to end up keeping parameters in a separate file, but I'm not sure how to best implement this. Any suggestions on how to effectively manage and document these scrapes would be greatly appreciated.", 'author_fullname': 't2_s9545lpak', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Best Practices for Organizing and Documenting Parameterized Scraper Output Files', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyotne', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716457059.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I am working on a project where I scrape data from multiple websites, using a separate `.py` script for each website. Each script varies certain parameters to perform &#39;incremental scrapes&#39; while keeping other parameters fixed. For example,</p>\n\n<ul>\n<li><p>Website A, I vary parameters like `DATE_FROM` and `DATE_TO` while keeping `TITLE`, `RATING`, and `PAGE_SIZE` fixed.</p></li>\n<li><p>Website B, I vary `YEAR` and `RATING`, and keep `TITLE` and `MAX_RESULTS` fixed.</p></li>\n<li><p>Website C, I don&#39;t vary any parameters.</p></li>\n</ul>\n\n<p>(In reality there are 50+ sites I am doing this for.)</p>\n\n<p>The results are dumped into separate directories for each website (`data/website_A/`, `data/website_B/`, etc.). Currently, I name the output files to include the varied parameters, which has resulted in complex and hard-to-read filenames. For example, in `data/website_A/`, I have filenames like:</p>\n\n<ol>\n<li><p>`1800-01-01_2002-01-01_loop_2002-01-02_2005-01-01.csv`</p></li>\n<li><p>`loop_2005-01-02_2010-01-01.csv`</p></li>\n</ol>\n\n<p>which is meant to indicate </p>\n\n<ol>\n<li><p>the scraper runs on `DATE_FROM = 1800-01-01` and `DATE_TO = 2002-01-01`, followed by a loop from `DATE_FROM = DATE_TO = 2002-01-02` to `DATE_FROM = DATE_TO = 2005-01-01`,</p></li>\n<li><p>the scraper runs on a loop from `DATE_FROM = DATE_TO = 2005-01-02` to `DATE_FROM = DATE_TO = 2010-01-01`</p></li>\n</ol>\n\n<p>but from these filenames, it&#39;s not immediately clear which parameters were varied and which were kept fixed. </p>\n\n<p>My questions are:</p>\n\n<ol>\n<li><p>What is the best practice for organizing these folders and files so that it&#39;s easy to identify which parameters were varied without cluttering the filenames?</p></li>\n<li><p>Is there a recommended way to log the parameters, both varied and fixed, for each scrape in a clear and maintainable manner?</p></li>\n</ol>\n\n<p>It seems like I will have to end up keeping parameters in a separate file, but I&#39;m not sure how to best implement this. Any suggestions on how to effectively manage and document these scrapes would be greatly appreciated.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cyotne', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='bebmfec'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyotne/best_practices_for_organizing_and_documenting/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyotne/best_practices_for_organizing_and_documenting/', 'subreddit_subscribers': 185504, 'created_utc': 1716457059.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.386+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hi All,  \nWe're excited to share that we've launched a DoubleCloud Managed Apache Airflow service designed to make your data workflow automation a breeze. Here‚Äôs what you can expect:\n\n \n\n* **Managed infrastructure**: We take care of cluster creation and updates so you can focus on your pipelines.\n* **Auto-Scaling**: No need to tweak settings for performance. Our worker nodes auto-scale based on your needs.\n* **Clear Insights**: Get easy access to logs and notifications with our user-friendly UI.\n* **Customizable**: Bring your own plugins, packages, or libraries by customizing the default container image.\n* **Rapid DAG Development**: Start quickly with pre-packaged common libraries and integrate them with your GIT setup effortlessly.\n* **Secure Environment**: Our workers and schedulers run in a secure setup.\n* **Integration**: Works smoothly with other DoubleCloud services to manage end-to-end data flows.  \n\n\n Find out all about it on our new service page: [https://double.cloud/services/managed-airflow/](https://double.cloud/services/managed-airflow/)  \nWe‚Äôre also offering a little something extra. If you try out our service and give us feedback, we'll send you a $50 Amazon voucher. Your input will help us fine-tune this service to better meet your needs.  \n\n\nJust drop me a message to discuss the details.  \n ", 'author_fullname': 't2_a4qx2du', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'New Managed Apache Airflow service', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyrek3', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.4, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716466776.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi All,<br/>\nWe&#39;re excited to share that we&#39;ve launched a DoubleCloud Managed Apache Airflow service designed to make your data workflow automation a breeze. Here‚Äôs what you can expect:</p>\n\n<ul>\n<li><strong>Managed infrastructure</strong>: We take care of cluster creation and updates so you can focus on your pipelines.</li>\n<li><strong>Auto-Scaling</strong>: No need to tweak settings for performance. Our worker nodes auto-scale based on your needs.</li>\n<li><strong>Clear Insights</strong>: Get easy access to logs and notifications with our user-friendly UI.</li>\n<li><strong>Customizable</strong>: Bring your own plugins, packages, or libraries by customizing the default container image.</li>\n<li><strong>Rapid DAG Development</strong>: Start quickly with pre-packaged common libraries and integrate them with your GIT setup effortlessly.</li>\n<li><strong>Secure Environment</strong>: Our workers and schedulers run in a secure setup.</li>\n<li><p><strong>Integration</strong>: Works smoothly with other DoubleCloud services to manage end-to-end data flows.  </p>\n\n<p>Find out all about it on our new service page: <a href="https://double.cloud/services/managed-airflow/">https://double.cloud/services/managed-airflow/</a><br/>\nWe‚Äôre also offering a little something extra. If you try out our service and give us feedback, we&#39;ll send you a $50 Amazon voucher. Your input will help us fine-tune this service to better meet your needs.  </p></li>\n</ul>\n\n<p>Just drop me a message to discuss the details.  </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/GHt1D6qhyqOLT9rNa08ayli01dcMM3P0o4RjwrXOO_M.jpg?auto=webp&s=a91f4a2774bc8ee2146a3e34515b1fbab8e68dd6', 'width': 2400, 'height': 1256}, 'resolutions': [{'url': 'https://external-preview.redd.it/GHt1D6qhyqOLT9rNa08ayli01dcMM3P0o4RjwrXOO_M.jpg?width=108&crop=smart&auto=webp&s=ce241b921995a82aa92c9b4d823d7a76765c3ef0', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/GHt1D6qhyqOLT9rNa08ayli01dcMM3P0o4RjwrXOO_M.jpg?width=216&crop=smart&auto=webp&s=b41bbf1dbccf4fe6f28da7885f9def621ae60fb9', 'width': 216, 'height': 113}, {'url': 'https://external-preview.redd.it/GHt1D6qhyqOLT9rNa08ayli01dcMM3P0o4RjwrXOO_M.jpg?width=320&crop=smart&auto=webp&s=8ccbc0a8e3af20473656b7c0fbe3d296832a2403', 'width': 320, 'height': 167}, {'url': 'https://external-preview.redd.it/GHt1D6qhyqOLT9rNa08ayli01dcMM3P0o4RjwrXOO_M.jpg?width=640&crop=smart&auto=webp&s=6b228181b54845f13b0a515dbd8070acfe5bf24b', 'width': 640, 'height': 334}, {'url': 'https://external-preview.redd.it/GHt1D6qhyqOLT9rNa08ayli01dcMM3P0o4RjwrXOO_M.jpg?width=960&crop=smart&auto=webp&s=c327106399b4215a5deb899f344d16e500ea10ff', 'width': 960, 'height': 502}, {'url': 'https://external-preview.redd.it/GHt1D6qhyqOLT9rNa08ayli01dcMM3P0o4RjwrXOO_M.jpg?width=1080&crop=smart&auto=webp&s=0af3120c770e9cc6b8d3e6c32462b96a71119d79', 'width': 1080, 'height': 565}], 'variants': {}, 'id': 'BcGF7W2uOTHwpzkas0xp0BBOs5g-O5wmsEbtKIPCFkc'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1cyrek3', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='deepanigi'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyrek3/new_managed_apache_airflow_service/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyrek3/new_managed_apache_airflow_service/', 'subreddit_subscribers': 185504, 'created_utc': 1716466776.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.386+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '[https://www.youtube.com/watch?v=bge4MPHnkno](https://www.youtube.com/watch?v=bge4MPHnkno)\n\nI managed to link Taylor Swift üíÉ into a sentence with Snowflake ‚ùÑÔ∏è Also - Snowflake Copilot üßë\u200d‚úàÔ∏è will ease your job\xa0Business\xa0Analyst or Data Engineer.\xa0See why in my latest video where I also used new editing tricks. Less hassle, more information.\n\nhttps://reddit.com/link/1cypebj/video/u1gm4685j52d1/player\n\nVideo contents for the busy ones:\n\nüìñ 00:00 Intro  \n‚ùÑÔ∏è 00:28 What is Snowflake Copilot?  \nüí¨ 01:37 Differences compared to ChatGPT?  \nüíÉ 02:23 Does Copilot know Taylor Swift?  \nüíé 03:27 What (other) benefits against the competition?  \n‚ùå 04:23 (current) limitations - part 1  \n‚ùå 05:25 (current) limitations - part 2  \nüñáÔ∏è 06:22 Cross Database queries  \nüå¨Ô∏è 07:06 Supported languages  \nüí≤ 07:47 Pricing  \nüéØ 08:07 Wrapping it up  \nüîÆ 08:36 Looking into the future', 'author_fullname': 't2_sxd6cnuh', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What is Snowflake Copilot and does it know Taylor Swift?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 105, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'u1gm4685j52d1': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/1cypebj/asset/u1gm4685j52d1/DASHPlaylist.mpd?a=1719129320%2CMDlmM2RmNjY5MjA3OGRkNDMxYTA0ODBhYjFkNzBmMGI2MTNjMjI5YTcwNDU4MWQ4MWFhMGIwZjJhYzliNTVlNg%3D%3D&v=1&f=sd', 'x': 1920, 'y': 1080, 'hlsUrl': 'https://v.redd.it/link/1cypebj/asset/u1gm4685j52d1/HLSPlaylist.m3u8?a=1719129320%2CMmM1NzNkMTI5NGYwMTJlOGNiZWQzZDEyMjkzNWIzZjM0NTIyZWYxOGU4Yjg1MTRkNjgxOTM3NmI3NTI2ODAxYw%3D%3D&v=1&f=sd', 'id': 'u1gm4685j52d1', 'isGif': False}}, 'name': 't3_1cypebj', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.44, 'author_flair_background_color': None, 'ups': 0, 'total_awards_received': 0, 'media_embed': {'content': '<iframe width="356" height="200" src="https://www.youtube.com/embed/bge4MPHnkno?feature=oembed&enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="What is Snowflake COPILOT and does it know Taylor Swift?"></iframe>', 'width': 356, 'scrolling': False, 'height': 200}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'What is Snowflake COPILOT and does it know Taylor Swift?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '<iframe width="356" height="200" src="https://www.youtube.com/embed/bge4MPHnkno?feature=oembed&enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="What is Snowflake COPILOT and does it know Taylor Swift?"></iframe>', 'author_name': 'Mika Heino', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/bge4MPHnkno/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/@MikaHeino'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '<iframe width="356" height="200" src="https://www.youtube.com/embed/bge4MPHnkno?feature=oembed&enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="What is Snowflake COPILOT and does it know Taylor Swift?"></iframe>', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/1cypebj', 'height': 200}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://a.thumbs.redditmedia.com/G5hNyjIsl-sgh8E6Qt0CfpiVvxrhBzOf_ceR6Td7HL8.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'subreddit_type': 'public', 'created': 1716459467.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p><a href="https://www.youtube.com/watch?v=bge4MPHnkno">https://www.youtube.com/watch?v=bge4MPHnkno</a></p>\n\n<p>I managed to link Taylor Swift üíÉ into a sentence with Snowflake ‚ùÑÔ∏è Also - Snowflake Copilot üßë\u200d‚úàÔ∏è will ease your job\xa0Business\xa0Analyst or Data Engineer.\xa0See why in my latest video where I also used new editing tricks. Less hassle, more information.</p>\n\n<p><a href="https://reddit.com/link/1cypebj/video/u1gm4685j52d1/player">https://reddit.com/link/1cypebj/video/u1gm4685j52d1/player</a></p>\n\n<p>Video contents for the busy ones:</p>\n\n<p>üìñ 00:00 Intro<br/>\n‚ùÑÔ∏è 00:28 What is Snowflake Copilot?<br/>\nüí¨ 01:37 Differences compared to ChatGPT?<br/>\nüíÉ 02:23 Does Copilot know Taylor Swift?<br/>\nüíé 03:27 What (other) benefits against the competition?<br/>\n‚ùå 04:23 (current) limitations - part 1<br/>\n‚ùå 05:25 (current) limitations - part 2<br/>\nüñáÔ∏è 06:22 Cross Database queries<br/>\nüå¨Ô∏è 07:06 Supported languages<br/>\nüí≤ 07:47 Pricing<br/>\nüéØ 08:07 Wrapping it up<br/>\nüîÆ 08:36 Looking into the future</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/BtQLnlUXYEkbnGrQoIJF7Yr3i2sC-XkbGX0T6KTTbj0.jpg?auto=webp&s=735c8c3af10d591353cc0d4c5eea5541090f461b', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/BtQLnlUXYEkbnGrQoIJF7Yr3i2sC-XkbGX0T6KTTbj0.jpg?width=108&crop=smart&auto=webp&s=680286805aaaa01da452e009dfaf9f9e1a1d72c1', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/BtQLnlUXYEkbnGrQoIJF7Yr3i2sC-XkbGX0T6KTTbj0.jpg?width=216&crop=smart&auto=webp&s=6d68e9b4b7a6f1d047f9a1c9eb5833491dbc195e', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/BtQLnlUXYEkbnGrQoIJF7Yr3i2sC-XkbGX0T6KTTbj0.jpg?width=320&crop=smart&auto=webp&s=ee55a62a62c735013ff331dd33976dc1b964e7f4', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'DAB6_5sTjiCWjyzXH-KJYpa09wNvSr8u4uyZCrYQ02w'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1cypebj', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Recordly_MHeino'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cypebj/what_is_snowflake_copilot_and_does_it_know_taylor/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cypebj/what_is_snowflake_copilot_and_does_it_know_taylor/', 'subreddit_subscribers': 185504, 'created_utc': 1716459467.0, 'num_crossposts': 0, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'What is Snowflake COPILOT and does it know Taylor Swift?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '<iframe width="356" height="200" src="https://www.youtube.com/embed/bge4MPHnkno?feature=oembed&enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="What is Snowflake COPILOT and does it know Taylor Swift?"></iframe>', 'author_name': 'Mika Heino', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/bge4MPHnkno/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/@MikaHeino'}}, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.386+0000] {logging_mixin.py:188} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0x7f33c03db520>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Is there anything to be passionate about in data engineering, is there any soul in it, is there anything in it for which it could be loved other than the money?', 'author_fullname': 't2_oaw3pjfwq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Can you love data engineering?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cyz74m', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.45, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1716487154.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Is there anything to be passionate about in data engineering, is there any soul in it, is there anything in it for which it could be loved other than the money?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cyz74m', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='grind_till_forbes'), 'discussion_type': None, 'num_comments': 25, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cyz74m/can_you_love_data_engineering/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cyz74m/can_you_love_data_engineering/', 'subreddit_subscribers': 185504, 'created_utc': 1716487154.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-05-24T07:45:02.398+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-24T07:45:02.399+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-24T07:45:02.435+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, run_id=scheduled__2024-05-23T00:00:00+00:00, execution_date=20240523T000000, start_date=20240524T005928, end_date=20240524T074502
[2024-05-24T07:45:02.536+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-24T07:45:02.597+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-24T07:45:02.601+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
